{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b68a58",
   "metadata": {},
   "source": [
    "## Explore tome and train models\n",
    "\n",
    "A tome consists of four things\n",
    "\n",
    "- **The keysets** - A simple list of keys that are included in this tome.\n",
    "- **The dataframes** - The data.\n",
    "- **The manifest** - A listing of availble keyset/dataframe files and other metadata about the tome.\n",
    "- **The header** - This provides the target list of keys while making the tome. Generally used by internal processes only. This is what makes tomes \"immutable\" once started or finished.\n",
    "\n",
    "Because they can be large, the combined dataframe data are saved in separate files called \"pages\". You can set a max (memory) size for each page when making a tome.\n",
    "\n",
    "Let's read in that tome and train a model to go from number of footsteps to rank, obviously.\n",
    "\n",
    "_**Run this notebook as-is.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461fd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pureskillgg_makenew_pyskill.notebook import setup_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25efcdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_notebook(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../usual_suspects.py\n",
    "# pylint: disable=unused-import\n",
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pureskillgg_dsdk.tome import create_tome_curator\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 150)\n",
    "pd.set_option(\"display.max_rows\", 150)\n",
    "pd.set_option(\"display.min_rows\", 150)\n",
    "# pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "curator = create_tome_curator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "footsteps_tome_name = 'footsteps_by_rank.2022-05-15,2022-05-15'\n",
    "df = curator.get_dataframe(footsteps_tome_name)\n",
    "keyset = curator.get_keyset(footsteps_tome_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd6dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df),len(keyset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2907a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa1640",
   "metadata": {},
   "source": [
    "## Explore the tome\n",
    "\n",
    "Let's look at footsteps as a function of rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a15e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unknown rank people\n",
    "df=df[df['rank']!=0]\n",
    "\n",
    "df['rank_fixed']=df['rank'].apply(lambda x: x/2).apply(round)\n",
    "\n",
    "gb = df[['rank','steps']].groupby('rank',as_index=False).mean()\n",
    "\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gb['rank'],gb['steps'])\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Average Number of Steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a652b",
   "metadata": {},
   "source": [
    "## Coaching time\n",
    "\n",
    "Obviously, any player that makes more than 1025 steps in a match is a pro, obviously and they deserve a 10/10 score. Anyone with less is a noob and will get a 1/10 score. We will do a toy example of applying this to one player in a match, which is how the Coach for PureSkill.gg works, mostly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fbac65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the functions from step 4\n",
    "from pureskillgg_makenew_pyskill.tutorial import (\n",
    "    aggregate_footsteps, \n",
    "    simplify_player_info,\n",
    "    get_map_name, \n",
    "    assemble_final_df\n",
    ")\n",
    "model_parameters={\n",
    "    'footstep_threshold':1025\n",
    "}\n",
    "\n",
    "def grade_footsteps(data, player_id_fixed):\n",
    "    df_footsteps_total = aggregate_footsteps(data['player_footstep'])\n",
    "    df_pi_simple = simplify_player_info(data['player_info'])\n",
    "    map_name = get_map_name(data['header'])\n",
    "    df_final = assemble_final_df(df_footsteps_total, df_pi_simple, map_name)\n",
    "    player_footstep_count = df_final[df_final['player_id_fixed']==player_id_fixed]['steps'].iat[0]\n",
    "    footstep_threshold = model_parameters['footstep_threshold']\n",
    "    if player_footstep_count > footstep_threshold:\n",
    "        return 1.0\n",
    "    return 0.1\n",
    "\n",
    "# Grab a test match to analyze.\n",
    "data = curator.get_random_match().get_channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d02b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_player = data['player_info']['player_id_fixed'][0]\n",
    "grade = grade_footsteps(data, random_player)\n",
    "if grade > 0.5:\n",
    "    print('congrats! you got a good grade.')\n",
    "else:\n",
    "    print('whoopsie, get gud kid.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
