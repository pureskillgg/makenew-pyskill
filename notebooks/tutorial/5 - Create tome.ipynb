{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065cdba6",
   "metadata": {},
   "source": [
    "## Create a tome for the footsteps data\n",
    "\n",
    "The general process for making a tome is:\n",
    "\n",
    "1. Choose a \"header tome\" as an index.\n",
    "1. Load the data from a match.\n",
    "1. Transform that data.\n",
    "1. Finalize results into a single data frame.\n",
    "1. Concat that dataframe with the others.\n",
    "1. Repeat from step 2 until no more matches remain.\n",
    "\n",
    "\n",
    "To make a tome, we use the `make_tome` function of the tome curator. This function handles reading the data science files, concatenating dataframes, writing tome pages, deciding when to write tome pages, and keeping track of matches included. We only need to provide the name of the tome we are making and the name of the header or subheader tome to serve as the index of matches. \n",
    "\n",
    "An important (but optional) parameter is the `ds_reading_instructions` where you only read in certain channels and columns for each match. This generally provides a drastic speed up because of how large some channels are, particularly `player_vector`, `player_status`, and `tick`. Avoiding reading those channels altogether will speed things up.\n",
    "\n",
    "It is possible that we don't want to include data from a match. In that case, you can pass `None` into the tome maker and this will acknowledge the match data as included without changing the data.\n",
    "\n",
    "_**Run this notebook as-is.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pureskillgg_makenew_pyskill.notebook import setup_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9361a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_notebook(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../usual_suspects.py\n",
    "# pylint: disable=unused-import\n",
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pureskillgg_dsdk.tome import create_tome_curator\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 150)\n",
    "pd.set_option(\"display.max_rows\", 150)\n",
    "pd.set_option(\"display.min_rows\", 150)\n",
    "# pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "curator = create_tome_curator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions from step 4\n",
    "from pureskillgg_makenew_pyskill.tutorial import (\n",
    "    aggregate_footsteps, \n",
    "    simplify_player_info,\n",
    "    get_map_name, \n",
    "    assemble_final_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b370ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our \"footsteps_by_rank\" tome\n",
    "tomer = curator.make_tome(\n",
    "    'footsteps_by_rank',\n",
    "    ds_reading_instructions=[\n",
    "        {\n",
    "            \"channel\": 'player_footstep',\n",
    "            \"columns\":['player_id_fixed']\n",
    "        },\n",
    "        {\n",
    "            \"channel\": 'player_info',\n",
    "            \"columns\":['player_id_fixed','commends_friendly','wins','rank']\n",
    "        },\n",
    "        {\n",
    "            \"channel\": 'header'\n",
    "        }\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade5c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each match and add our processed dataframe to \n",
    "for data, key in tomer.iterate():\n",
    "    df_footsteps_total = aggregate_footsteps(data['player_footstep'])\n",
    "    df_pi_simple = simplify_player_info(data['player_info'])\n",
    "    map_name = get_map_name(data['header'])\n",
    "    df_final = assemble_final_df(df_footsteps_total, df_pi_simple, map_name)\n",
    "    df_final['match_key'] = key\n",
    "    tomer.concat(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9103febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = curator.get_dataframe('footsteps_by_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fff1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020978a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
