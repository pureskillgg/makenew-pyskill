{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab9ec32b",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "**FPS Critic Inc., makers of PureSkill.gg, is not liable for any AWS costs your incur. Run this notebook only if you understand and accept the AWS billing implications.**\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64833230",
   "metadata": {},
   "source": [
    "## Getting data from the ADX\n",
    "\n",
    "This notebook will help you download data from the main dataset off of the data exchange.\n",
    "\n",
    "Here are the definition of some of the terms around data on the AWS Data Exchange (ADX):\n",
    "- Data Exchange: AWS service that hosts the data.\n",
    "- Data Product: This is our listing on the ADX where we are publishing the csds data.\n",
    "- Data Set: A container for one type of data.\n",
    "- Revision: For the csds data, each revision is equivalent to one day of data. This allows for granularity for both data volume and date range.\n",
    "\n",
    "This notebook will show you how to transfer some set of revisions from the ADX to a bucket on S3. It will also allow you to enable automatic transferring for new revisions to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e40206",
   "metadata": {},
   "source": [
    "## You will incur costs!\n",
    "\n",
    "While the data set subscription as provided is free, **exporting and downloading the data set will incur a real money cost to your AWS bill according to their pricing**. Even if you are on the AWS free tier, the volume of data in this data set may exceed the free tier limits.\n",
    "\n",
    "Things that will most likely cost money:\n",
    "- Transferring from ADX to your S3 bucket\n",
    "- Storing the data in S3\n",
    "- Transferring from your S3 bucket to your local hard drive\n",
    "\n",
    "\n",
    "For example, the month of april is:\n",
    "\n",
    "- 275 GB\n",
    "- 286,671 files\n",
    "- 8,717 matches\n",
    "\n",
    "\n",
    "You may use [this calculator](https://calculator.aws) to estimate your costs tailored to your account and region:  For full S3 pricing, refer to [the amazon pricing page](https://aws.amazon.com/s3/pricing/)\n",
    "\n",
    "We have included a calculator below to assist you in calculating your costs, however, we do not guarantee its accuracy and **you** are responsible for the final calculations of your cost and paying your AWS bill."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeba4c2",
   "metadata": {},
   "source": [
    "## Data Volume\n",
    "\n",
    "For example, here are the number of matches in each month for the first five months:\n",
    "\n",
    "- December 2021: 17,952\n",
    "- January 2022: 15,315\n",
    "- February 2022: 9,892\n",
    "- March 2022: 16,855\n",
    "- April 2022: 8,717\n",
    "\n",
    "For the first bunch of revisions we uploaded, we made a [documentation website](https://docs.pureskill.gg/datascience/adx/csgo/matches_per_day) showing the approximate number of matches for each day. There is quite a large variance in some days due to promotions or other campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"f49be2ef387af522a7b6f000158113e0\"\n",
    "bucket = 'my-bucket'\n",
    "prefix = None\n",
    "start_date=\"2022-04-01\"\n",
    "end_date=\"2022-05-01\"\n",
    "days_to_store_on_s3 = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b08e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pureskillgg_makenew_pyskill.notebook import setup_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d70b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fa887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pureskillgg_dsdk import (\n",
    "    enable_auto_exporting_adx_dataset_revisions_to_s3,\n",
    "    disable_auto_exporting_adx_dataset_revisions_to_s3,\n",
    "    download_adx_dataset_revision,\n",
    "    get_adx_dataset_revisions,\n",
    "    export_single_adx_dataset_revision_to_s3,\n",
    "    export_multiple_adx_dataset_revisions_to_s3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4193db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs = get_adx_dataset_revisions(dataset_id, start_date=start_date, end_date=end_date)\n",
    "number_of_revisions=len(revs)\n",
    "print('There are',number_of_revisions,'revisions in that date range.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603c1ae",
   "metadata": {},
   "source": [
    "## Specific Cost Estimate\n",
    "\n",
    "We provide the estimates below for convienence but do not guarantee their accuracy or applicability to your AWS account. You should perform your own calculations using the cost calculator provided by AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300805ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From AWS\n",
    "cost_per_get = 0.0000004 # for US East (Virginia)\n",
    "cost_per_put = 0.000005 # for US East (Virginia)\n",
    "cost_per_gb_per_month = 0.023 # for US East (Virginia)\n",
    "cost_per_gb_transfer_from_adx = 0.00 # for US East (Virginia)\n",
    "cost_per_gb_transfer_out = 0.09 # for US East (Virginia)\n",
    "\n",
    "## Estimate for example EU region\n",
    "# cost_per_get = 0.00000042 # for EU (Paris)\n",
    "# cost_per_put = 0.0000053 # for EU (Paris)\n",
    "# cost_per_gb_per_month = 0.024 # for EU (Paris)\n",
    "# cost_per_gb_transfer_from_adx = 0.02 # for EU (Paris)\n",
    "# cost_per_gb_transfer_out = 0.09 # for EU (Paris)\n",
    "\n",
    "## Estimate for example Asia Pacific region\n",
    "# cost_per_get = 0.00000035 # for Asia Pacific (Seoul)\n",
    "# cost_per_put = 0.0000045 # for Asia Pacific (Seoul)\n",
    "# cost_per_gb_per_month = 0.025 # for Asia Pacific (Seoul)\n",
    "# cost_per_gb_transfer_from_adx = 0.08 # for Asia Pacific (Seoul)\n",
    "# cost_per_gb_transfer_out = 0.11 # for Asia Pacific (Seoul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46091bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_per_revision = 8717/30 # April average\n",
    "# matches_per_revision = 9892/28 # Feb average\n",
    "GB_per_match = 0.03154\n",
    "files_per_match = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_per_month = 30\n",
    "\n",
    "number_of_matches = number_of_revisions*matches_per_revision\n",
    "number_of_files = number_of_matches*files_per_match\n",
    "storage_volume_GB = number_of_matches*GB_per_match\n",
    "\n",
    "storage_cost = storage_volume_GB*cost_per_gb_per_month*days_to_store_on_s3/days_per_month\n",
    "\n",
    "transfer_put_cost = cost_per_put*number_of_files\n",
    "transfer_get_cost = cost_per_get*number_of_files\n",
    "\n",
    "transfer_volume_cost = storage_volume_GB*cost_per_gb_transfer_from_adx\n",
    "\n",
    "download_cost = storage_volume_GB*cost_per_gb_transfer_out\n",
    "\n",
    "print(f\"{number_of_revisions} revisions will be {round(storage_volume_GB,2)} GB, \"\n",
    "     f\"{number_of_matches} matches, and {number_of_files} files.\")\n",
    "print(f\"Cost to transfer to your S3 bucket: ${round(transfer_put_cost+transfer_volume_cost,3)}\")\n",
    "print(f\"Cost to store data in S3 for {days_to_store_on_s3} days: ${round(storage_cost,3)}\")\n",
    "print(f\"Cost to transfer from S3 to local: ${round(transfer_get_cost+download_cost,3)}\")\n",
    "print(f\"Total cost: ${round(transfer_put_cost+transfer_volume_cost+storage_cost+transfer_get_cost+download_cost,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1413df7e",
   "metadata": {},
   "source": [
    "## Transferring revisions from Data Exchange to your S3 bucket\n",
    "\n",
    "By uncommenting the code below, you agree to pay whatever AWS costs you will incur by running this notebook. \n",
    "\n",
    "**‚ö†Ô∏èüíµ‚ö†Ô∏è Uncommenting the code below in this notebook will cause you to incur AWS usage fees! ‚ö†Ô∏èüíµ‚ö†Ô∏è**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50124c08",
   "metadata": {},
   "source": [
    "### Transfer latest revision from ADX to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_single_adx_dataset_revision_to_s3(\n",
    "#     bucket, dataset_id, prefix=prefix\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_single_adx_dataset_revision_to_s3(\n",
    "#     bucket, dataset_id, revision_id=revs[0] prefix=prefix\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba0f4b",
   "metadata": {},
   "source": [
    "### Transfer a specific day from ADX to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_multiple_adx_dataset_revisions_to_s3(\n",
    "#     bucket,\n",
    "#     dataset_id,\n",
    "#     prefix=prefix,\n",
    "#     start_date=\"2022-04-08\", #Edit this date\n",
    "#     end_date=\"2022-04-08\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e0fad2",
   "metadata": {},
   "source": [
    "### Transfer everything from ADX to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_multiple_adx_dataset_revisions_to_s3(\n",
    "#     bucket,\n",
    "#     dataset_id,\n",
    "#     prefix=prefix\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f2787",
   "metadata": {},
   "source": [
    "## Transferring data from S3 to local\n",
    "\n",
    "There are many many ways to do this so we won't list them all here. We generally sync one month at a time with the AWS CLI like this:\n",
    "\n",
    "```\n",
    "aws s3 sync s3://my-bucket/csds/2022/04/ .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f815be8f",
   "metadata": {},
   "source": [
    "## Transferring single revision from ADX to local (not recommended)\n",
    "\n",
    "This is not recommended because it will take a **VERY VERY** long time to download. Please instead download from your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_collection_path = os.environ.get('PURESKILLGG_TOME_DS_COLLECTION_PATH')\n",
    "# download_adx_dataset_revision(ds_collection_path, dataset_id, prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f6bc2",
   "metadata": {},
   "source": [
    "## Automatically export revisions to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812acb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable_auto_exporting_adx_dataset_revisions_to_s3(bucket, dataset_id, prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236ff45",
   "metadata": {},
   "source": [
    "## Disable exporting of revisions to s3\n",
    "\n",
    "You can cancel your automatic exporting of revisions by running the code below. \n",
    "\n",
    "You can also disable this automatic job through the AWS console by:\n",
    "\n",
    "1. navigating to the ADX, \n",
    "1. clicking on \"Entitled data\" under \"My Subscriptions\"\n",
    "1. Click on \"PureSkill.gg Competitive CS:GO Gameplay\"\n",
    "1. Click on the data set which should be named \"pureskillgg-csgo-production-dataexchange-csds-0\"\n",
    "1. Scroll down to \"Jobs\" and you should be able to cancel any outstanding jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12664988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable_auto_exporting_adx_dataset_revisions_to_s3(dataset_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
